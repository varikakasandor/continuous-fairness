{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ERM with DNN under penalty of Equalized Odds</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement here a regular Empirical Risk Minimization (ERM) of a Deep Neural Network (DNN) penalized to enforce an Equalized Odds constraint. More formally, given a dataset of size $n$ consisting of context features $x$, target $y$ and a sensitive information $a$ to protect, we want to solve\n",
    "$$\n",
    "\\text{argmin}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^n \\ell(y_i, h(x_i)) + \\lambda \\chi^2|_1\n",
    "$$\n",
    "where $\\ell$ is for instance the MSE and the penalty is\n",
    "$$\n",
    "\\chi^2|_1 = \\left\\lVert\\chi^2\\left(\\hat{\\pi}(h(x)|y, a|y), \\hat{\\pi}(h(x)|y)\\otimes\\hat{\\pi}(a|y)\\right)\\right\\rVert_1\n",
    "$$\n",
    "where $\\hat{\\pi}$ denotes the empirical density estimated through a Gaussian KDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "\n",
    "from examples.data_loading import read_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "We use here the _communities and crimes_ dataset that can be found on the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/communities+and+crime). Non-predictive information, such as city name, state... have been removed and the file is at the arff format for ease of loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, a_train, x_test, y_test, a_test = read_dataset(name='crimes', fold=1)\n",
    "n, d = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Deep Neural Network\n",
    "\n",
    "We define a very simple DNN for regression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NetRegression, self).__init__()\n",
    "        size = 50\n",
    "        self.first = nn.Linear(input_size, size)\n",
    "        self.fc = nn.Linear(size, size)\n",
    "        self.last = nn.Linear(size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.selu(self.first(x))\n",
    "        out = F.selu(self.fc(out))\n",
    "        out = self.last(out)\n",
    "        out = torch.sigmoid(out) # NEW\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fairness-penalized ERM\n",
    "\n",
    "We now implement the full learning loop. The regression loss used is the quadratic loss with a L2 regularization and the fairness-inducing penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_learning(x_train, y_train, a_train, model, fairness_metric, fairness_weight = 1.0, lr=1e-5, num_epochs=10, print_progress = True):    \n",
    "    X = torch.tensor(x_train.astype(np.float32))\n",
    "    A = torch.tensor(a_train.astype(np.float32))\n",
    "    Y = torch.tensor(y_train.astype(np.float32))\n",
    "    dataset = data_utils.TensorDataset(X, Y, A)\n",
    "    dataset_loader = data_utils.DataLoader(dataset=dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "    # mse regression objective\n",
    "    data_fitting_loss = nn.MSELoss()\n",
    "\n",
    "    # stochastic optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "    for j in range(num_epochs):\n",
    "        if print_progress:\n",
    "            print(f\"EPOCH {j} started\")\n",
    "        for i, (x, y, a) in enumerate(dataset_loader):\n",
    "            if print_progress:\n",
    "                print(f\"Batch {i} started\")\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(x).flatten()\n",
    "                loss = data_fitting_loss(prediction, y)\n",
    "                loss += fairness_weight * fairness_metric(prediction, a, y)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "For the evaluation on the test set, we compute two metrics: the MSE (accuracy) and HGR$|_\\infty$ (fairness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y, a, fairness_metric):\n",
    "    X = torch.tensor(x.astype(np.float32))\n",
    "    A = torch.Tensor(a.astype(np.float32))\n",
    "    Y = torch.tensor(y.astype(np.float32))\n",
    "\n",
    "    prediction = model(X).detach().flatten()\n",
    "    loss = nn.MSELoss()(prediction, Y)\n",
    "    discrimination = fairness_metric(prediction, A, Y)\n",
    "    return loss.item(), discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fairness_metric(constrained_intervals_A, quantizition_intervals_Y, train, size_compensation = lambda x: np.sqrt(x)):\n",
    "    \n",
    "    def inside(num, endpoints):\n",
    "        start, end = endpoints\n",
    "        return start <= num and num < end\n",
    "    \n",
    "    def fairness_metric(Y_hat, A, Y):\n",
    "        nd_losses = []\n",
    "        n = len(Y_hat)\n",
    "        for inter_Y in quantizition_intervals_Y:\n",
    "            for inter_A in constrained_intervals_A:\n",
    "                cnt_y_a = 0\n",
    "                cnt_y = 0\n",
    "                sum_y_yhat = 0\n",
    "                sum_y_a_yhat = 0\n",
    "                for i in range(len(Y_hat)): # could be sped up by combining with outer loop\n",
    "                    if inside(Y[i], inter_Y):\n",
    "                        cnt_y += 1\n",
    "                        sum_y_yhat += Y_hat[i]\n",
    "                        if inside(A[i], inter_A):\n",
    "                            cnt_y_a += 1\n",
    "                            sum_y_a_yhat += Y_hat[i]\n",
    "                if cnt_y_a > 0 and cnt_y > 0:\n",
    "                    curr_nd_loss = torch.abs(sum_y_a_yhat / cnt_y_a - sum_y_yhat / cnt_y) * size_compensation(cnt_y_a / n)\n",
    "                    nd_losses.append(curr_nd_loss)\n",
    "        nd_losses_torch = torch.tensor(nd_losses)\n",
    "        return torch.mean(nd_losses_torch) if train else torch.max(nd_losses_torch)\n",
    "    return fairness_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_constrained_intervals(num_constrained_intervals):\n",
    "    endpoints = np.linspace(0, 1, num_constrained_intervals + 1)\n",
    "    constrained_intervals = []\n",
    "    for i in range(len(endpoints) - 1):\n",
    "        constrained_intervals.append((endpoints[i], endpoints[i + 1]))\n",
    "    return constrained_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 1 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 2 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 3 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 4 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 5 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 6 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 7 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 8 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 9 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 10 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 11 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 12 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 13 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 14 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 15 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 16 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 17 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 18 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n",
      "EPOCH 19 started\n",
      "Batch 0 started\n",
      "Batch 1 started\n",
      "Batch 2 started\n",
      "Batch 3 started\n",
      "Batch 4 started\n",
      "Batch 5 started\n",
      "Batch 6 started\n",
      "Batch 7 started\n",
      "Batch 8 started\n"
     ]
    }
   ],
   "source": [
    "model = NetRegression(d, 1)\n",
    "num_epochs = 20\n",
    "lr = 1e-5\n",
    "fairness_weight = 1\n",
    "num_constrained_intervals = 10\n",
    "intervals = generate_constrained_intervals(num_constrained_intervals)\n",
    "fairness_metric_train = generate_fairness_metric(intervals, intervals, True)\n",
    "fairness_metric_test = generate_fairness_metric(intervals, intervals, False)\n",
    "\n",
    "model = regularized_learning(x_train, y_train, a_train, model=model, fairness_metric=fairness_metric_train, lr=lr, \\\n",
    "                             num_epochs=num_epochs, fairness_weight=fairness_weight)\n",
    "mse, discrimination = evaluate(model, x_test, y_test, a_test, fairness_metric=fairness_metric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE:{} Beta loss:{}\".format(mse, discrimination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
