{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ERM with DNN under penalty of Equalized Odds</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement here a regular Empirical Risk Minimization (ERM) of a Deep Neural Network (DNN) penalized to enforce an Equalized Odds constraint. More formally, given a dataset of size $n$ consisting of context features $x$, target $y$ and a sensitive information $a$ to protect, we want to solve\n",
    "$$\n",
    "\\text{argmin}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^n \\ell(y_i, h(x_i)) + \\lambda \\chi^2|_1\n",
    "$$\n",
    "where $\\ell$ is for instance the MSE and the penalty is\n",
    "$$\n",
    "\\chi^2|_1 = \\left\\lVert\\chi^2\\left(\\hat{\\pi}(h(x)|y, a|y), \\hat{\\pi}(h(x)|y)\\otimes\\hat{\\pi}(a|y)\\right)\\right\\rVert_1\n",
    "$$\n",
    "where $\\hat{\\pi}$ denotes the empirical density estimated through a Gaussian KDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "\n",
    "from examples.data_loading import read_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "We use here the _communities and crimes_ dataset that can be found on the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/communities+and+crime). Non-predictive information, such as city name, state... have been removed and the file is at the arff format for ease of loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, a_train, x_test, y_test, a_test = read_dataset(name='crimes', fold=1)\n",
    "n, d = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Deep Neural Network\n",
    "\n",
    "We define a very simple DNN for regression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NetRegression, self).__init__()\n",
    "        size = 50\n",
    "        self.first = nn.Linear(input_size, size)\n",
    "        self.fc = nn.Linear(size, size)\n",
    "        self.last = nn.Linear(size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.selu(self.first(x))\n",
    "        out = F.selu(self.fc(out))\n",
    "        out = self.last(out)\n",
    "        out = torch.sigmoid(out) # NEW\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fairness-penalized ERM\n",
    "\n",
    "We now implement the full learning loop. The regression loss used is the quadratic loss with a L2 regularization and the fairness-inducing penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_learning(x_train, y_train, a_train, model, fairness_metric_train, fairness_metric_test, fairness_weight = 1.0, lr=1e-5, num_epochs=10, print_progress = True):    \n",
    "    X = torch.tensor(x_train.astype(np.float32))\n",
    "    A = torch.tensor(a_train.astype(np.float32))\n",
    "    Y = torch.tensor(y_train.astype(np.float32))\n",
    "    dataset = data_utils.TensorDataset(X, Y, A)\n",
    "    dataset_loader = data_utils.DataLoader(dataset=dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "    # mse regression objective\n",
    "    data_fitting_loss = nn.MSELoss()\n",
    "\n",
    "    # stochastic optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "    for j in range(num_epochs):\n",
    "        if print_progress:\n",
    "            print(f\"EPOCH {j} started\")\n",
    "        for i, (x, y, a) in enumerate(dataset_loader):\n",
    "            # if print_progress:\n",
    "            #    print(f\"Batch {i} started\")\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(x).flatten()\n",
    "                loss = fairness_weight * fairness_metric_train(prediction, a, y) + data_fitting_loss(prediction, y)\n",
    "                loss.backward()\n",
    "                \"\"\"for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        print(f\"Parameter: {name}\\nGradient: {param.grad}\\n\")\"\"\"\n",
    "                return loss\n",
    "            optimizer.step(closure)\n",
    "        mse_curr, nd_curr = evaluate(model, x_test, y_test, a_test, fairness_metric=fairness_metric_test)\n",
    "        print(f\"mse: {mse_curr}, nd: {nd_curr}, combined: {mse_curr + fairness_weight * nd_curr}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "For the evaluation on the test set, we compute two metrics: the MSE (accuracy) and HGR$|_\\infty$ (fairness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y, a, fairness_metric):\n",
    "    X = torch.tensor(x.astype(np.float32))\n",
    "    A = torch.Tensor(a.astype(np.float32))\n",
    "    Y = torch.tensor(y.astype(np.float32))\n",
    "\n",
    "    prediction = model(X).detach().flatten()\n",
    "    loss = nn.MSELoss()(prediction, Y)\n",
    "    discrimination = fairness_metric(prediction, A, Y)\n",
    "    return loss.item(), discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fairness_metric(constrained_intervals_A, quantizition_intervals_Y, train, size_compensation = lambda x: np.sqrt(x)):\n",
    "    \n",
    "    def inside(num, endpoints):\n",
    "        start, end = endpoints\n",
    "        return start <= num and num < end\n",
    "    \n",
    "    def fairness_metric(Y_hat, A, Y):\n",
    "        nd_losses = []\n",
    "        n = len(Y_hat)\n",
    "        for inter_Y in quantizition_intervals_Y:\n",
    "            for inter_A in constrained_intervals_A:\n",
    "                cnt_y_a = 0\n",
    "                cnt_y = 0\n",
    "                sum_y_yhat = 0\n",
    "                sum_y_a_yhat = 0\n",
    "                for i in range(len(Y_hat)): # could be sped up by combining with outer loop\n",
    "                    if inside(Y[i], inter_Y):\n",
    "                        cnt_y += 1\n",
    "                        sum_y_yhat += Y_hat[i]\n",
    "                        if inside(A[i], inter_A):\n",
    "                            cnt_y_a += 1\n",
    "                            sum_y_a_yhat += Y_hat[i]\n",
    "                # print(inter_Y, inter_A, cnt_y, cnt_y_a)\n",
    "                if cnt_y_a > 0 and cnt_y > 0:\n",
    "                    curr_nd_loss = torch.abs(sum_y_a_yhat / cnt_y_a - sum_y_yhat / cnt_y) * size_compensation(cnt_y_a / n)\n",
    "                    nd_losses.append(curr_nd_loss)\n",
    "        nd_losses_torch = torch.stack(nd_losses)\n",
    "        return torch.mean(nd_losses_torch) if train else torch.max(nd_losses_torch)\n",
    "    return fairness_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_constrained_intervals(num_constrained_intervals):\n",
    "    endpoints = np.linspace(0, 1, num_constrained_intervals + 1)\n",
    "    constrained_intervals = []\n",
    "    for i in range(len(endpoints) - 1):\n",
    "        constrained_intervals.append((endpoints[i], endpoints[i + 1]))\n",
    "    return constrained_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started\n",
      "mse: 0.12971177697181702, nd: 0.005482755601406097, combined: 0.184539332985878\n",
      "EPOCH 1 started\n",
      "mse: 0.128629669547081, nd: 0.0047569251619279385, combined: 0.17619892954826355\n",
      "EPOCH 2 started\n",
      "mse: 0.1275639683008194, nd: 0.004030788317322731, combined: 0.1678718477487564\n",
      "EPOCH 3 started\n",
      "mse: 0.1265244483947754, nd: 0.0033072440419346094, combined: 0.15959689021110535\n",
      "EPOCH 4 started\n",
      "mse: 0.1255127489566803, nd: 0.0026167347095906734, combined: 0.1516800969839096\n",
      "EPOCH 5 started\n",
      "mse: 0.12463998794555664, nd: 0.001991408411413431, combined: 0.14455407857894897\n",
      "EPOCH 6 started\n",
      "mse: 0.12381522357463837, nd: 0.0014226344646885991, combined: 0.13804157078266144\n",
      "EPOCH 7 started\n",
      "mse: 0.12295719236135483, nd: 0.0008402536623179913, combined: 0.13135972619056702\n",
      "EPOCH 8 started\n",
      "mse: 0.12225601077079773, nd: 0.0009659646893851459, combined: 0.13191565871238708\n",
      "EPOCH 9 started\n",
      "mse: 0.12156471610069275, nd: 0.0010645337169989944, combined: 0.13221004605293274\n",
      "EPOCH 10 started\n",
      "mse: 0.12099391967058182, nd: 0.0011181392474099994, combined: 0.13217531144618988\n",
      "EPOCH 11 started\n",
      "mse: 0.12051084637641907, nd: 0.0011783040827140212, combined: 0.13229387998580933\n",
      "EPOCH 12 started\n",
      "mse: 0.1200176253914833, nd: 0.001198387355543673, combined: 0.13200150430202484\n",
      "EPOCH 13 started\n",
      "mse: 0.11946401745080948, nd: 0.001313789514824748, combined: 0.13260191679000854\n",
      "EPOCH 14 started\n",
      "mse: 0.11893394589424133, nd: 0.0015147975645959377, combined: 0.1340819150209427\n",
      "EPOCH 15 started\n",
      "mse: 0.11853153258562088, nd: 0.001576562994159758, combined: 0.13429716229438782\n",
      "EPOCH 16 started\n",
      "mse: 0.1182931438088417, nd: 0.00156091817189008, combined: 0.13390232622623444\n",
      "EPOCH 17 started\n",
      "mse: 0.11797794699668884, nd: 0.0016609872691333294, combined: 0.134587824344635\n",
      "EPOCH 18 started\n",
      "mse: 0.11777830868959427, nd: 0.0016766320914030075, combined: 0.13454462587833405\n",
      "EPOCH 19 started\n",
      "mse: 0.11751562356948853, nd: 0.0017221840098500252, combined: 0.13473746180534363\n",
      "EPOCH 20 started\n",
      "mse: 0.11733218282461166, nd: 0.001694719074293971, combined: 0.13427937030792236\n",
      "EPOCH 21 started\n",
      "mse: 0.11717978119850159, nd: 0.0017012535827234387, combined: 0.1341923177242279\n",
      "EPOCH 22 started\n",
      "mse: 0.11701352894306183, nd: 0.0016177993966266513, combined: 0.1331915259361267\n",
      "EPOCH 23 started\n",
      "mse: 0.11677612364292145, nd: 0.0016556794289499521, combined: 0.13333292305469513\n",
      "EPOCH 24 started\n",
      "mse: 0.11655542999505997, nd: 0.0017707912484183908, combined: 0.13426333665847778\n",
      "EPOCH 25 started\n",
      "mse: 0.11634764075279236, nd: 0.0018073442624881864, combined: 0.13442108035087585\n",
      "EPOCH 26 started\n",
      "mse: 0.11611336469650269, nd: 0.0019536232575774193, combined: 0.13564959168434143\n",
      "EPOCH 27 started\n",
      "mse: 0.11591048538684845, nd: 0.002010766416788101, combined: 0.13601815700531006\n",
      "EPOCH 28 started\n",
      "mse: 0.11569107323884964, nd: 0.002101379679515958, combined: 0.13670486211776733\n",
      "EPOCH 29 started\n",
      "mse: 0.11534816771745682, nd: 0.0022614523768424988, combined: 0.1379626989364624\n",
      "EPOCH 30 started\n",
      "mse: 0.11514551937580109, nd: 0.002315713092684746, combined: 0.13830265402793884\n",
      "EPOCH 31 started\n",
      "mse: 0.11487571895122528, nd: 0.0024959747679531574, combined: 0.13983546197414398\n",
      "EPOCH 32 started\n",
      "mse: 0.11463969200849533, nd: 0.002628147602081299, combined: 0.14092117547988892\n",
      "EPOCH 33 started\n",
      "mse: 0.11460099369287491, nd: 0.0025199828669428825, combined: 0.1398008167743683\n",
      "EPOCH 34 started\n",
      "mse: 0.11449867486953735, nd: 0.0024901204742491245, combined: 0.13939988613128662\n",
      "EPOCH 35 started\n",
      "mse: 0.11434296518564224, nd: 0.0025088763795793056, combined: 0.13943172991275787\n",
      "EPOCH 36 started\n",
      "mse: 0.11424099653959274, nd: 0.002441568998619914, combined: 0.13865669071674347\n",
      "EPOCH 37 started\n",
      "mse: 0.11409532278776169, nd: 0.002444434678182006, combined: 0.13853967189788818\n",
      "EPOCH 38 started\n",
      "mse: 0.11406513303518295, nd: 0.002324918285012245, combined: 0.1373143196105957\n",
      "EPOCH 39 started\n",
      "mse: 0.11382020264863968, nd: 0.002428957261145115, combined: 0.13810977339744568\n",
      "EPOCH 40 started\n",
      "mse: 0.11351992934942245, nd: 0.0025655347853899, combined: 0.13917528092861176\n",
      "EPOCH 41 started\n",
      "mse: 0.11348709464073181, nd: 0.002417443785816431, combined: 0.13766153156757355\n",
      "EPOCH 42 started\n",
      "mse: 0.11348069459199905, nd: 0.0022500392515212297, combined: 0.13598108291625977\n",
      "EPOCH 43 started\n",
      "mse: 0.11329808086156845, nd: 0.0022280828561633825, combined: 0.135578915476799\n",
      "EPOCH 44 started\n",
      "mse: 0.113099604845047, nd: 0.0022473016288131475, combined: 0.1355726271867752\n",
      "EPOCH 45 started\n",
      "mse: 0.11298026144504547, nd: 0.002209215424954891, combined: 0.13507241010665894\n",
      "EPOCH 46 started\n",
      "mse: 0.11282039433717728, nd: 0.0021872478537261486, combined: 0.13469287753105164\n",
      "EPOCH 47 started\n",
      "mse: 0.11268110573291779, nd: 0.002119974000379443, combined: 0.1338808536529541\n",
      "EPOCH 48 started\n",
      "mse: 0.11235415190458298, nd: 0.0022603929974138737, combined: 0.13495808839797974\n",
      "EPOCH 49 started\n",
      "mse: 0.11219050735235214, nd: 0.00223040790297091, combined: 0.1344945877790451\n",
      "EPOCH 50 started\n",
      "mse: 0.11205229163169861, nd: 0.0022010027896612883, combined: 0.13406231999397278\n",
      "EPOCH 51 started\n",
      "mse: 0.1120901107788086, nd: 0.002045842120423913, combined: 0.132548525929451\n",
      "EPOCH 52 started\n",
      "mse: 0.11198832839727402, nd: 0.002022670116275549, combined: 0.13221502304077148\n",
      "EPOCH 53 started\n",
      "mse: 0.11198398470878601, nd: 0.001863695913925767, combined: 0.13062094151973724\n",
      "EPOCH 54 started\n",
      "mse: 0.11184310913085938, nd: 0.0017975257942453027, combined: 0.1298183649778366\n",
      "EPOCH 55 started\n",
      "mse: 0.11159918457269669, nd: 0.0017964831786230206, combined: 0.12956401705741882\n",
      "EPOCH 56 started\n",
      "mse: 0.1113857850432396, nd: 0.0018560574389994144, combined: 0.12994635105133057\n",
      "EPOCH 57 started\n",
      "mse: 0.11112768203020096, nd: 0.0019584514666348696, combined: 0.13071219623088837\n",
      "EPOCH 58 started\n",
      "mse: 0.110765740275383, nd: 0.0021650909911841154, combined: 0.13241665065288544\n",
      "EPOCH 59 started\n",
      "mse: 0.11053720116615295, nd: 0.002216229448094964, combined: 0.13269948959350586\n",
      "EPOCH 60 started\n",
      "mse: 0.11051443964242935, nd: 0.002075381111353636, combined: 0.13126824796199799\n",
      "EPOCH 61 started\n",
      "mse: 0.11036012321710587, nd: 0.002054071519523859, combined: 0.13090083003044128\n",
      "EPOCH 62 started\n",
      "mse: 0.11023970693349838, nd: 0.001973661594092846, combined: 0.1299763172864914\n",
      "EPOCH 63 started\n",
      "mse: 0.11009179055690765, nd: 0.0019211737671867013, combined: 0.12930352985858917\n",
      "EPOCH 64 started\n",
      "mse: 0.10991952568292618, nd: 0.0019085619132965803, combined: 0.12900514900684357\n",
      "EPOCH 65 started\n",
      "mse: 0.10986865311861038, nd: 0.001839258475229144, combined: 0.1282612383365631\n",
      "EPOCH 66 started\n",
      "mse: 0.10978418588638306, nd: 0.0018151443218812346, combined: 0.12793563306331635\n",
      "EPOCH 67 started\n",
      "mse: 0.10963478684425354, nd: 0.001820625038817525, combined: 0.1278410404920578\n",
      "EPOCH 68 started\n",
      "mse: 0.10949632525444031, nd: 0.0018241655780002475, combined: 0.12773798406124115\n",
      "EPOCH 69 started\n",
      "mse: 0.10919546335935593, nd: 0.0020390565041452646, combined: 0.12958602607250214\n",
      "EPOCH 70 started\n",
      "mse: 0.10910610109567642, nd: 0.002037389436736703, combined: 0.12947998940944672\n",
      "EPOCH 71 started\n",
      "mse: 0.10899659991264343, nd: 0.0020618659909814596, combined: 0.12961526215076447\n",
      "EPOCH 72 started\n",
      "mse: 0.10887473076581955, nd: 0.00204455410130322, combined: 0.12932026386260986\n",
      "EPOCH 73 started\n",
      "mse: 0.10877566039562225, nd: 0.002032126300036907, combined: 0.12909692525863647\n",
      "EPOCH 74 started\n",
      "mse: 0.1087627187371254, nd: 0.0018809018656611443, combined: 0.1275717318058014\n",
      "EPOCH 75 started\n",
      "mse: 0.10877051949501038, nd: 0.0017088083550333977, combined: 0.1258586049079895\n",
      "EPOCH 76 started\n",
      "mse: 0.10867615044116974, nd: 0.001654352410696447, combined: 0.1252196729183197\n",
      "EPOCH 77 started\n",
      "mse: 0.10856641829013824, nd: 0.0015964452177286148, combined: 0.1245308667421341\n",
      "EPOCH 78 started\n",
      "mse: 0.10838370025157928, nd: 0.0016827763756737113, combined: 0.1252114623785019\n",
      "EPOCH 79 started\n",
      "mse: 0.10826000571250916, nd: 0.001691401586867869, combined: 0.12517401576042175\n",
      "EPOCH 80 started\n",
      "mse: 0.10810914635658264, nd: 0.0016965422546491027, combined: 0.125074565410614\n",
      "EPOCH 81 started\n",
      "mse: 0.10794269293546677, nd: 0.0017793328734114766, combined: 0.1257360279560089\n",
      "EPOCH 82 started\n",
      "mse: 0.10794953256845474, nd: 0.001645465032197535, combined: 0.1244041845202446\n",
      "EPOCH 83 started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.10780078172683716, nd: 0.001676041167229414, combined: 0.12456119060516357\n",
      "EPOCH 84 started\n",
      "mse: 0.10744552314281464, nd: 0.0018897948320955038, combined: 0.1263434737920761\n",
      "EPOCH 85 started\n",
      "mse: 0.10725725442171097, nd: 0.0019270391203463078, combined: 0.12652763724327087\n",
      "EPOCH 86 started\n",
      "mse: 0.10714548826217651, nd: 0.0018847991013899446, combined: 0.12599347531795502\n",
      "EPOCH 87 started\n",
      "mse: 0.10700961947441101, nd: 0.0019347110064700246, combined: 0.12635673582553864\n",
      "EPOCH 88 started\n",
      "mse: 0.10692167282104492, nd: 0.0019421711331233382, combined: 0.12634338438510895\n",
      "EPOCH 89 started\n",
      "mse: 0.10682743042707443, nd: 0.0019600125961005688, combined: 0.126427561044693\n",
      "EPOCH 90 started\n",
      "mse: 0.10683954507112503, nd: 0.0018397268140688539, combined: 0.12523680925369263\n",
      "EPOCH 91 started\n",
      "mse: 0.10662498325109482, nd: 0.0019439999014139175, combined: 0.1260649859905243\n",
      "EPOCH 92 started\n",
      "mse: 0.1064852699637413, nd: 0.001967216143384576, combined: 0.12615743279457092\n",
      "EPOCH 93 started\n",
      "mse: 0.1064569279551506, nd: 0.0018998529994860291, combined: 0.12545545399188995\n",
      "EPOCH 94 started\n",
      "mse: 0.10641912370920181, nd: 0.0018819612450897694, combined: 0.12523873150348663\n",
      "EPOCH 95 started\n",
      "mse: 0.10645852982997894, nd: 0.0017466883873566985, combined: 0.12392541766166687\n",
      "EPOCH 96 started\n",
      "mse: 0.10625892877578735, nd: 0.0017468667356297374, combined: 0.12372759729623795\n",
      "EPOCH 97 started\n",
      "mse: 0.1059526801109314, nd: 0.0018892651423811913, combined: 0.12484533339738846\n",
      "EPOCH 98 started\n",
      "mse: 0.10574548691511154, nd: 0.0019632463809102774, combined: 0.12537795305252075\n",
      "EPOCH 99 started\n",
      "mse: 0.1056821271777153, nd: 0.0018467073095962405, combined: 0.12414920330047607\n"
     ]
    }
   ],
   "source": [
    "model = NetRegression(d, 1)\n",
    "num_epochs = 100\n",
    "lr = 1e-5\n",
    "fairness_weight = 10\n",
    "num_constrained_intervals = 2\n",
    "intervals = generate_constrained_intervals(num_constrained_intervals)\n",
    "fairness_metric_train = generate_fairness_metric(intervals, intervals, True)\n",
    "fairness_metric_test = generate_fairness_metric(intervals, intervals, False)\n",
    "\n",
    "model = regularized_learning(x_train, y_train, a_train, model=model, fairness_metric_train=fairness_metric_train, fairness_metric_test=fairness_metric_test, lr=lr, \\\n",
    "                             num_epochs=num_epochs, fairness_weight=fairness_weight)\n",
    "mse, discrimination = evaluate(model, x_test, y_test, a_test, fairness_metric=fairness_metric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetRegression(d, 1)\n",
    "num_epochs = 100\n",
    "lr = 1e-5\n",
    "fairness_weight = 10\n",
    "num_constrained_intervals = 2\n",
    "intervals = generate_constrained_intervals(num_constrained_intervals)\n",
    "fairness_metric_train = generate_fairness_metric(intervals, intervals, True)\n",
    "fairness_metric_test = generate_fairness_metric(intervals, intervals, False)\n",
    "\n",
    "model = regularized_learning(x_train, y_train, a_train, model=model, fairness_metric_train=fairness_metric_train, fairness_metric_test=fairness_metric_test, lr=lr, \\\n",
    "                             num_epochs=num_epochs, fairness_weight=fairness_weight)\n",
    "mse, discrimination = evaluate(model, x_test, y_test, a_test, fairness_metric=fairness_metric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:0.13390439748764038 Beta loss:0.005223618820309639\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE:{} Beta loss:{}\".format(mse, discrimination))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m q\n",
      "\u001b[1;31mNameError\u001b[0m: name 'q' is not defined"
     ]
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + 4 * b\n",
    "d = 5 * a + b\n",
    "l = [c, d]\n",
    "t = torch.tensor(l)\n",
    "q = torch.mean(t)\n",
    "q.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)\n",
    "print(r)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baba = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "kaka = torch.tensor([3.0, 4.0], requires_grad=True)\n",
    "t = torch.sum(baba*kaka)\n",
    "r = torch.sum(baba / kaka)\n",
    "q = torch.mean(torch.tensor([t, r], requires_grad = True))\n",
    "q.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baba._grad, kaka._grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "c = a + 4 * b\n",
    "d = 5 * a + b\n",
    "\n",
    "# Set requires_grad=True for c and d\n",
    "c.retain_grad()\n",
    "d.retain_grad()\n",
    "\n",
    "l = [c, d]\n",
    "t = torch.tensor(l)\n",
    "q = torch.mean(t)\n",
    "q.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param._grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with requires_grad=True\n",
    "t = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# Perform seven differentiable calculations on t\n",
    "calculation1 = t * 2\n",
    "calculation2 = t ** 2\n",
    "calculation3 = torch.sin(t)\n",
    "calculation4 = t / 2\n",
    "calculation5 = torch.exp(t)\n",
    "calculation6 = torch.cos(t)\n",
    "calculation7 = t + 1\n",
    "\n",
    "# Store the results in a list\n",
    "results = [calculation1, calculation2, calculation3, calculation4, calculation5, calculation6, calculation7]\n",
    "\n",
    "# Compute the mean of the results\n",
    "mean_result = torch.mean(torch.stack(results))\n",
    "\n",
    "# Perform the backward pass on the mean\n",
    "mean_result.backward()\n",
    "\n",
    "# Access the gradient of t\n",
    "gradient_wrt_t = t.grad\n",
    "\n",
    "# Print the gradient with respect to t\n",
    "print(\"Gradient with respect to t:\", gradient_wrt_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(torch.stack(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
